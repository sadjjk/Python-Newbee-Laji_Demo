# Demo1-小说自动续写(文本预测)

#### 表面上：(纯属忽悠，你若上当，概不负责)

​	没错！就是自动续写。给我一篇小说/诗歌/歌词，不限英语/日语/中文，甚至是脚本代码，只要是文本格式，都能还一你篇充满想象的续写。可指定任意开头词，可任意指定续写字数。好吧，准确地，不是续写，是自由发挥。

```shell
''' 周杰伦歌词_自由发挥 '''
我知道
我的世界 一种解
我一直实现 语不是我
有什么(客) 我只是一口
我想想我不来 你的微笑
我说 你我你的你

'''古诗_自由发挥'''
何人无不见，此地自何如。
一夜山边去，江山一夜归。
山风春草色，秋水夜声深。
何事同相见，应知旧子人。
```



#### ==实际上：==(透过现象看本质)

- 结果上：从实践结果看，效果并不是十分理想。当然也可能是训练次数有限，超参不合适等原因造成。续写出来的句子时而“我靠！天才啊，这句都能编出来” 时而“MDZZ，这句子造出来都读不通啊”   更多的时候，造出来的句子没法看，尤其是小说。小说的词非常多，矩阵会非常稀疏，预测效果相当差。更进一步尤其是中文小说，因为中文字实在是太多，加了一层embedding，效果嘛，还是呵呵呵，预测出来拼在一起的句子实在是不通。由单个字为最小单位(英文以单个字为最小单位 就非常好 大小写加标点字符 最多不超过100个)改为以单个词为最小单位，使用分词，预测结果上 语句会更通顺流畅，但分词后的词组就更加爆炸了，比中文字还要多。
- 模型上：使用非常非常简单的人造2层(参数可调)LSTM。极其简陋的神经网络层*(为什么不用高大上的model，因为我不会呀)* 。文本的预测其实就是找到映射关系，这里的映射关系也很粗暴 整个句子，从第1个字映射到第2个字，第2个字映射第3个字,...,最后一个字映射回第一个字 。如从<u>*“天凉了 雨下了 你走了”*</u>到<u>*“凉了 雨下了 你走了 天”*</u>   。找到映射关系后，如何预测，根据给出的指定开头词，取开头词的最后一个，根据映射关系找出这个词最有可能的TOPN个词，再从这N个词中随便选一个。选出来后，再根据这个词寻找下一个可能的词，直到满足指定个数。
- 思路上：文本预测在整体思路上没什么问题，由于各个功能组件都非常的简陋，导致整体结果较差，因此这只是小小的尝试窥探，**仅供娱乐**。

#### Code：

​	[Github](https://github.com/sadjjk/LSTM_txt.git)

​	https://github.com/sadjjk/LSTM_txt.git

​	Run:

```shell
python train.py --input_file "文件.txt"
python test.py --start_string "开头词"
```

​	鸣谢[hzy46](https://github.com/hzy46) 及他的[项目](https://github.com/hzy46/Char-RNN-TensorFlow)、[NELSONZHAO](https://github.com/NELSONZHAO)及他的[项目](https://github.com/NELSONZHAO/zhihu/tree/master/anna_lstm)

​	源码都是来自他们，仅做了少量的参数修改

​	虽然他们根本不认识我

PS：*这个拖延了一个多月的的Demo，终于要收尾。再不收尾，我该抽自己了。坐下电脑前，觉得自己还有救，码下了这些字。代码上使用的还是最底层的tensorflow,所以代码量非常多。*

```python
import tensorflow as tf  #使用这包就有个好处 美名其曰TFBOYS 
```

